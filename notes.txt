Gracefully stopping... (press Ctrl+C again to force)
[+] Stopping 2/2
 ✔ Container app       Stopped                                                         0.0s 
 ✔ Container postgres  Stopped                                                         0.2s 
MacBook-Pro-L:btlz-wb-test ls$ clear
MacBook-Pro-L:btlz-wb-test ls$ clear
MacBook-Pro-L:btlz-wb-test ls$ docker compose down --rmi local --volumes
[+] Running 5/5
 ✔ Container app                      Remov...                 0.0s 
 ✔ Container postgres                 Removed                  0.0s 
 ✔ Image btlz-wb-test-app:latest      Removed                  0.0s 
 ✔ Network btlz-wb-test_postgres-net  Removed                  0.2s 
 ✔ Volume btlz-wb-test_postgres-vol   Removed                  0.0s 
MacBook-Pro-L:btlz-wb-test ls$ docker compose up --build
Compose can now delegate builds to bake for better performance.
 To do so, set COMPOSE_BAKE=true.
[+] Building 9.3s (16/16) FINISHED             docker:desktop-linux
 => [app internal] load build definition from Dockerfile       0.0s
 => => transferring dockerfile: 415B                           0.0s
 => [app internal] load metadata for docker.io/library/node:2  0.8s
 => [app internal] load .dockerignore                          0.0s
 => => transferring context: 90B                               0.0s
 => [app deps-prod 1/4] FROM docker.io/library/node:20-alpine  0.0s
 => [app internal] load build context                          0.0s
 => => transferring context: 5.21kB                            0.0s
 => CACHED [app deps-prod 2/4] WORKDIR /app                    0.0s
 => CACHED [app deps-prod 3/4] COPY ./package*.json .          0.0s
 => CACHED [app deps-prod 4/4] RUN npm install --omit=dev      0.0s
 => [app build 1/3] RUN npm install --include=dev              6.7s
 => [app build 2/3] COPY . .                                   0.0s
 => [app build 3/3] RUN npm run build                          1.5s
 => CACHED [app prod 3/5] COPY --from=build /app/package*.jso  0.0s
 => CACHED [app prod 4/5] COPY --from=deps-prod /app/node_mod  0.0s
 => [app prod 5/5] COPY --from=build /app/dist ./dist          0.0s
 => [app] exporting to image                                   0.0s
 => => exporting layers                                        0.0s
 => => writing image sha256:2794f7c327d47f4b99c72a4b437d4f291  0.0s
 => => naming to docker.io/library/btlz-wb-test-app            0.0s
 => [app] resolving provenance for metadata file               0.0s
[+] Running 5/5
 ✔ app                                 Built                   0.0s 
 ✔ Network btlz-wb-test_postgres-net   Created                 0.0s 
 ✔ Volume "btlz-wb-test_postgres-vol"  Created                 0.0s 
 ✔ Container postgres                  Created                 0.0s 
 ✔ Container app                       Crea...                 0.0s 
Attaching to app, postgres
postgres  | The files belonging to this database system will be owned by user "postgres".
postgres  | This user must also own the server process.
postgres  | 
postgres  | The database cluster will be initialized with locale "en_US.utf8".
postgres  | The default database encoding has accordingly been set to "UTF8".
postgres  | The default text search configuration will be set to "english".
postgres  | 
postgres  | Data page checksums are disabled.
postgres  | 
postgres  | fixing permissions on existing directory /var/lib/postgresql/data/pgdata ... ok
postgres  | creating subdirectories ... ok
postgres  | selecting dynamic shared memory implementation ... posix
postgres  | selecting default max_connections ... 100
postgres  | selecting default shared_buffers ... 128MB
postgres  | selecting default time zone ... UTC
postgres  | creating configuration files ... ok
postgres  | running bootstrap script ... ok
postgres  | sh: locale: not found
postgres  | 2025-07-03 22:16:08.219 UTC [31] WARNING:  no usable system locales were found
postgres  | performing post-bootstrap initialization ... ok
postgres  | initdb: warning: enabling "trust" authentication for local connections
postgres  | initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
postgres  | syncing data to disk ... ok
postgres  | 
postgres  | 
postgres  | Success. You can now start the database server using:
postgres  | 
postgres  |     pg_ctl -D /var/lib/postgresql/data/pgdata -l logfile start
postgres  | 
postgres  | waiting for server to start....2025-07-03 22:16:08.483 UTC [37] LOG:  starting PostgreSQL 16.1 on aarch64-unknown-linux-musl, compiled by gcc (Alpine 13.2.1_git20231014) 13.2.1 20231014, 64-bit
postgres  | 2025-07-03 22:16:08.483 UTC [37] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
postgres  | 2025-07-03 22:16:08.486 UTC [40] LOG:  database system was shut down at 2025-07-03 22:16:08 UTC
postgres  | 2025-07-03 22:16:08.488 UTC [37] LOG:  database system is ready to accept connections
postgres  |  done
postgres  | server started
postgres  | 
postgres  | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
postgres  | 
postgres  | waiting for server to shut down....2025-07-03 22:16:08.593 UTC [37] LOG:  received fast shutdown request
postgres  | 2025-07-03 22:16:08.594 UTC [37] LOG:  aborting any active transactions
postgres  | 2025-07-03 22:16:08.595 UTC [37] LOG:  background worker "logical replication launcher" (PID 43) exited with exit code 1
postgres  | 2025-07-03 22:16:08.596 UTC [38] LOG:  shutting down
postgres  | 2025-07-03 22:16:08.597 UTC [38] LOG:  checkpoint starting: shutdown immediate
postgres  | 2025-07-03 22:16:08.600 UTC [38] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.005 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/14F0480, redo lsn=0/14F0480
postgres  | 2025-07-03 22:16:08.602 UTC [37] LOG:  database system is shut down
postgres  |  done
postgres  | server stopped
postgres  | 
postgres  | PostgreSQL init process complete; ready for start up.
postgres  | 
postgres  | 2025-07-03 22:16:08.713 UTC [1] LOG:  starting PostgreSQL 16.1 on aarch64-unknown-linux-musl, compiled by gcc (Alpine 13.2.1_git20231014) 13.2.1 20231014, 64-bit
postgres  | 2025-07-03 22:16:08.714 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
postgres  | 2025-07-03 22:16:08.714 UTC [1] LOG:  listening on IPv6 address "::", port 5432
postgres  | 2025-07-03 22:16:08.715 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
postgres  | 2025-07-03 22:16:08.718 UTC [51] LOG:  database system was shut down at 2025-07-03 22:16:08 UTC
postgres  | 2025-07-03 22:16:08.721 UTC [1] LOG:  database system is ready to accept connections
app       | 
app       | > btlz-test@1.0.0 start
app       | > node dist/app.js
app       | 
app       | Batch 1 ran the following migrations:
app       | - 20250227184908_spreadsheets.js
app       | Ran 1 seed files
app       | - spreadsheets.js
app       | All migrations and seeds have been run
postgres  | 2025-07-03 22:21:08.802 UTC [49] LOG:  checkpoint starting: time
postgres  | 2025-07-03 22:21:19.568 UTC [49] LOG:  checkpoint complete: wrote 107 buffers (0.7%); 0 WAL file(s) added, 0 removed, 0 recycled; write=10.748 s, sync=0.011 s, total=10.766 s; sync files=55, longest=0.002 s, average=0.001 s; distance=461 kB, estimate=461 kB; lsn=0/1563A30, redo lsn=0/15639F8

Судя по логам, PostgreSQL успешно инициализируется и запускается, принимает подключения (строка `database system is ready to accept connections`), а контейнер `app` запускает приложение и выполняет миграции без ошибок.

Если хотите проверить именно логи подключения к базе (успешные или неудачные попытки подключения), то по умолчанию PostgreSQL пишет такие сообщения в логи, но уровень логирования может быть не очень подробным.

---

### Как включить более подробное логирование подключений в PostgreSQL (в Docker)

1. Добавьте в `docker-compose.yaml` для сервиса `postgres` переменную окружения или команду, чтобы включить подробные логи:

Например, можно переопределить параметры через `command`:

```yaml
services:
  postgres:
    image: postgres:16.1-alpine
    environment:
      POSTGRES_USER: youruser
      POSTGRES_PASSWORD: yourpassword
      POSTGRES_DB: yourdb
    command:
      - postgres
      - -c
      - log_connections=on
      - -c
      - log_disconnections=on
      - -c
      - log_statement=all
    ...
```

Или использовать конфигурационный файл `postgresql.conf` с нужными параметрами (более сложно).

2. Перезапустите контейнер:

```bash
docker compose down
docker compose up -d
```

3. Теперь в логах контейнера `postgres` будут появляться сообщения о каждом подключении и отключении, а также все SQL-запросы.

---

### Просмотр логов подключения

```bash
docker compose logs -f postgres
```

В логах вы увидите строки вида:

```
LOG:  connection authorized: user=youruser database=yourdb application_name=psql
LOG:  disconnection: session time: ...
```

Если есть ошибки авторизации, они тоже будут видны.

---

### Итог

- Логи из вашего вывода показывают, что база запускается и работает.
- Для детального логирования подключений включите `log_connections` и `log_disconnections`.
- После этого смотрите логи контейнера `postgres` через `docker compose logs postgres`.

Если нужно, могу помочь с точной настройкой.


В логах, которые вы показали, видна инициализация и нормальный запуск PostgreSQL, а затем его корректное выключение (fast shutdown request). Однако нет сообщений о подключениях клиентов (например, вашего приложения) или SQL-запросах.

Это значит, что в текущей конфигурации PostgreSQL не логирует подключения и запросы.

---

### Что делать, чтобы увидеть логи подключений и запросов?

1. **Включить логирование подключений и отключений**  
Добавьте в `docker-compose.yml` для сервиса postgres параметры конфигурации:

```yaml
services:
  postgres:
    image: postgres:16.1-alpine
    environment:
      POSTGRES_USER: youruser
      POSTGRES_PASSWORD: yourpassword
      POSTGRES_DB: yourdb
    command:
      - postgres
      - -c
      - log_connections=on
      - -c
      - log_disconnections=on
      - -c
      - log_statement=all
```

Это заставит PostgreSQL логировать все подключения, отключения и все SQL-запросы.

2. **Перезапустить контейнеры:**

```bash
docker compose down
docker compose up -d
```

3. **Посмотреть логи снова:**

```bash
docker compose logs -f postgres
```

Теперь в логах должны появиться строки вида:

```
LOG: connection authorized: user=youruser database=yourdb application_name=yourapp
LOG: disconnection: session time: ...
LOG: statement: SELECT ...
```

---

### Почему в текущих логах нет подключений?

- Логи показывают только старт и остановку сервера.
- Возможно, приложение не подключается к базе или подключается, но PostgreSQL не логирует эти события по умолчанию.
- Включение `log_connections` и `log_statement` даст больше информации.

---

### Дополнительно

- В логах есть предупреждение `sh: locale: not found` и `no usable system locales were found`. Это связано с образом Alpine и не критично, но можно решить, установив пакет `locales` или `glibc` в образе, если нужно.
- Если приложение запускается и миграции выполняются (как в ваших предыдущих логах), значит подключение к базе есть — просто его не видно в логах.

---

Если хотите, могу помочь с точным примером `docker-compose.yml` для вашего случая.

// Добавленна типизация в knex.ts для migrate и seed
interface MigrationResult {
  batch: number;
  migrations: string[];
}








создать сервис, выполняющий 2 задачи:
регулярное получение информации о тарифах wb и сохранение их в БД на каждый день;
регулярное обновление информации о актуальных тарифах в google-таблицах.

Входные данные

СУБД - PostgreSQL.
Библиотека для работы с СУБД knex.js
Описание типов - typescript.
Endpoint: https://common-api.wildberries.ru/api/v1/tariffs/box 
(Тарифы для коробов )

Обращение к google-таблицам для выгрузки данных из PostgreSQL должно производится по их идентификатору. Количество таблиц - N.
Приложение запускается и работает в docker контейнерах. вот все файлы с скаченного шаблона src/config/knex/knexfile.ts import env from "#config/env/env";
import { Knex } from "knex";
import { z } from "zod";

const connectionSchema = z.object({
  host: z.string(),
  port: z.number(),
  database: z.string(),
  user: z.string(),
  password: z.string(),
});

const NODE_ENV = env.NODE_ENV ?? "development";

const knegConfigs: Record<typeof NODE_ENV, Knex.Config> = {
  development: {
    client: "pg",
    connection: () =>
      connectionSchema.parse({
        host: env.POSTGRES_HOST ?? "localhost",
        port: env.POSTGRES_PORT ?? 5432,
        database: env.POSTGRES_DB ?? "postgres",
        user: env.POSTGRES_USER ?? "postgres",
        password: env.POSTGRES_PASSWORD ?? "postgres",
      }),
    pool: {
      min: 2,
      max: 10,
    },
    migrations: {
      stub: "src/config/knex/migration.stub.js",
      directory: "./src/postgres/migrations",
      tableName: "migrations",
      extension: "ts",
    },
    seeds: {
      stub: "src/config/knex/seed.stub.js",
      directory: "./src/postgres/seeds",
      extension: "js",
    },
  },
  production: {
    client: "pg",
    connection: () =>
      connectionSchema.parse({
        host: env.POSTGRES_HOST,
        port: env.POSTGRES_PORT,
        database: env.POSTGRES_DB,
        user: env.POSTGRES_USER,
        password: env.POSTGRES_PASSWORD,
      }),
    pool: {
      min: 2,
      max: 10,
    },
    migrations: {
      stub: "dist/config/knex/migration.stub.js",
      directory: "./dist/postgres/migrations",
      tableName: "migrations",
      extension: "js",
    },
    seeds: {
      stub: "src/config/knex/seed.stub.js",
      directory: "./dist/postgres/seeds",
      extension: "js",
    },
  },
};

export default knegConfigs[NODE_ENV];
вот postgres/ knex.ts. import _knex from "knex";
import knexConfig from "#config/knex/knexfile";

const knex = _knex(knexConfig);

// Типизация для migrate и seed
interface MigrationResult {
  batch: number;
  migrations: string[];
}

export default knex;

function logMigrationResults(action: string, result: [number, string[]]) {
  if (result[1].length === 0) {
    console.log(
      ["latest", "up"].includes(action)
        ? "All migrations are up to date"
        : "All migrations have been rolled back"
    );
    return;
  }
  console.log(
    `Batch ${result[0]} ${["latest", "up"].includes(action) ? "ran" : "rolled back"} the following migrations:`
  );
  for (const migration of result[1]) {
    console.log("- " + migration);
  }
}
function logMigrationList(list: [{ name: string }[], { file: string }[]]) {
  console.log(`Found ${list[0].length} Completed Migration file/files.`);
  for (const migration of list[0]) {
    console.log("- " + migration.name);
  }
  console.log(`Found ${list[1].length} Pending Migration file/files.`);
  for (const migration of list[1]) {
    console.log("- " + migration.file);
  }
}

function logSeedRun(result: [string[]]) {
  if (result[0].length === 0) {
    console.log("No seeds to run");
  }
  console.log(`Ran ${result[0].length} seed files`);
  for (const seed of result[0]) {
    console.log("- " + seed?.split(/\/|\\/).pop());
  }
  // Ran 5 seed files
}

function logSeedMake(name: string) {
  console.log(`Created seed: ${name.split(/\/|\\/).pop()}`);
}

export const migrate = {
  latest: async () => {
    logMigrationResults("latest", await knex.migrate.latest());
  },
  rollback: async () => {
    logMigrationResults("rollback", await knex.migrate.rollback());
  },
  down: async (name?: string) => {
    logMigrationResults("down", await knex.migrate.down({ name }));
  },
  up: async (name?: string) => {
    logMigrationResults("up", await knex.migrate.up({ name }));
  },
  list: async () => {
    logMigrationList(await knex.migrate.list());
  },
  make: async (name: string) => {
    if (!name) {
      console.error("Please provide a migration name");
      process.exit(1);
    }
    console.log(await knex.migrate.make(name, { extension: "js" }));
  },
};

export const seed = {
  run: async () => {
    logSeedRun(await knex.seed.run());
  },
  make: async (name: string) => {
    if (!name) {
      console.error("Please provide a seed name");
      process.exit(1);
    }
    logSeedMake(await knex.seed.make(name));
  },
};
а вот utils/knex.ts. import { migrate, seed } from "#postgres/knex";
import { Command } from "commander";
const program = new Command();

program
  .command("migrate")
  .argument("[type]", "latest|rollback|status|down|up|list")
  .argument("[arg]", "version")
  .action(async (action, arg) => {
    if (!action) return;
    if (action === "latest") await migrate.latest();
    if (action === "rollback") await migrate.rollback();
    if (action === "down") await migrate.down(arg);
    if (action === "up") await migrate.up(arg);
    if (action === "list") await migrate.list();
    if (action === "make") await migrate.make(arg);
    process.exit(0);
  });
program.command("seed [action] [arg]").action(async (action, arg) => {
  if (!action) return;
  if (action === "run") await seed.run();
  if (action === "make") await seed.make(arg);
  process.exit(0);
});
program.command("default", { isDefault: true }).action(() => {});
program.parse();
и вот файл app.ts  import knex, { migrate, seed } from "#postgres/knex";

await migrate.latest();
await seed.run();

console.log("All migrations and seeds have been run");
Я предоставил тебе все эти файлы для того что бы ты сразу понял в чем проблема. Покажи  пожалуйста готовый сервис для данного  knex
обновление сервиа для получения информации о тарифах надо сделать каждые 12 чаосв
а обновлени таблиц каждые 6 часов


Спасибо за предоставленную информацию. Я понимаю, что нужно создать сервис на TypeScript с использованием Knex.js и PostgreSQL, который будет:

1. Регулярно получать тарифы Wildberries по API `https://common-api.wildberries.ru/api/v1/tariffs/box` и сохранять их в базу данных.
2. Регулярно обновлять данные из БД в Google Sheets по N таблицам (идентификаторам).

---

## Что я сделаю

- Опишу структуру таблицы для тарифов.
- Создам миграцию для таблицы.
- Напишу сервис для получения тарифов и сохранения их в БД.
- Реализую сервис для обновления Google Sheets (через Google Sheets API).
- Настрою расписание (cron) для периодического запуска этих задач.
- Использую ваши настройки knex и env.

---

# 1. Миграция для таблицы тарифов

Создайте миграцию `create_tariffs_table.ts` в `src/postgres/migrations/`:

```ts
import { Knex } from "knex";

export async function up(knex: Knex): Promise<void> {
  return knex.schema.createTable("tariffs", (table) => {
    table.increments("id").primary();
    table.string("tariff_id").notNullable().index(); // уникальный id тарифа из API
    table.string("name").notNullable();
    table.decimal("price", 10, 2).notNullable();
    table.jsonb("raw_data").notNullable(); // для хранения всей информации
    table.date("date").notNullable().index(); // дата, на которую актуален тариф
    table.timestamps(true, true);
    table.unique(["tariff_id", "date"]); // уникальность тарифа на дату
  });
}

export async function down(knex: Knex): Promise<void> {
  return knex.schema.dropTableIfExists("tariffs");
}
```

---

# 2. Типы TypeScript для тарифов

Создайте файл `src/types/tariffs.ts`:

```ts
export interface Tariff {
  tariff_id: string; // id тарифа из API
  name: string;
  price: number;
  [key: string]: any; // остальные поля
}
```

---

# 3. Сервис для получения тарифов и сохранения в БД

Создайте файл `src/services/tariffsService.ts`:

```ts
import axios from "axios";
import knex from "#postgres/knex";
import { Tariff } from "#types/tariffs";

const WB_TARIFFS_URL = "https://common-api.wildberries.ru/api/v1/tariffs/box";

export async function fetchTariffsFromWB(): Promise<Tariff[]> {
  const response = await axios.get(WB_TARIFFS_URL);
  // Предполагаем, что API возвращает массив тарифов в response.data
  return response.data;
}

export async function saveTariffsToDB(tariffs: Tariff[], date: Date): Promise<void> {
  // Для простоты, будем использовать upsert (Postgres ON CONFLICT)
  for (const tariff of tariffs) {
    await knex("tariffs")
      .insert({
        tariff_id: tariff.tariff_id,
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        date,
      })
      .onConflict(["tariff_id", "date"])
      .merge({
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        updated_at: knex.fn.now(),
      });
  }
}

export async function updateTariffs(): Promise<void> {
  const tariffs = await fetchTariffsFromWB();
  const today = new Date();
  const dateString = today.toISOString().split("T")[0]; // yyyy-mm-dd
  await saveTariffsToDB(tariffs, new Date(dateString));
  console.log(`Tariffs updated for date ${dateString}`);
}
```

---

# 4. Сервис для обновления Google Sheets

Для работы с Google Sheets нам нужна авторизация через OAuth2 или сервисный аккаунт.

Создайте файл `src/services/googleSheetsService.ts`:

```ts
import { google, sheets_v4 } from "googleapis";
import knex from "#postgres/knex";

const SCOPES = ["https://www.googleapis.com/auth/spreadsheets"];
const GOOGLE_SHEETS_CREDENTIALS = process.env.GOOGLE_SHEETS_CREDENTIALS || ""; // JSON в env
const GOOGLE_SHEETS_TOKEN = process.env.GOOGLE_SHEETS_TOKEN || ""; // JSON в env

// Парсим credentials
const credentials = JSON.parse(GOOGLE_SHEETS_CREDENTIALS);

const auth = new google.auth.GoogleAuth({
  credentials,
  scopes: SCOPES,
});

const sheets = google.sheets({ version: "v4", auth });

interface SheetInfo {
  id: string; // Идентификатор Google таблицы
  name?: string; // Опционально имя листа
}

// Предположим, что у нас есть таблица в БД с id таблиц Google Sheets
// Для примера, создадим тип и функцию получения этих id
export async function getGoogleSheetIds(): Promise<SheetInfo[]> {
  // Здесь можно хранить таблицы в отдельной таблице БД, например google_sheets
  // Для примера жестко возвращаем массив
  return [
    { id: "sheetId1", name: "Лист1" },
    { id: "sheetId2", name: "Тарифы" },
    // ...
  ];
}

/**
 * Получить тарифы из БД для конкретной даты
 */
export async function getTariffsFromDB(date: Date): Promise<any[]> {
  const dateString = date.toISOString().split("T")[0];
  return knex("tariffs")
    .select("tariff_id", "name", "price")
    .where("date", dateString);
}

/**
 * Обновить данные в Google Sheet
 */
export async function updateGoogleSheet(sheetId: string, data: any[][]): Promise<void> {
  // Очистим лист (например, 'Sheet1')
  const range = "Sheet1!A1";

  // Запишем данные
  await sheets.spreadsheets.values.update({
    spreadsheetId: sheetId,
    range,
    valueInputOption: "USER_ENTERED",
    requestBody: {
      values: data,
    },
  });
}

/**
 * Основная функция обновления всех Google Sheets
 */
export async function updateGoogleSheetsForTariffs(date: Date): Promise<void> {
  const sheetsInfo = await getGoogleSheetIds();
  const tariffs = await getTariffsFromDB(date);

  // Формируем данные для Google Sheets: заголовки + данные
  const values = [["Tariff ID", "Name", "Price"]];
  for (const t of tariffs) {
    values.push([t.tariff_id, t.name, t.price.toString()]);
  }

  for (const sheet of sheetsInfo) {
    await updateGoogleSheet(sheet.id, values);
    console.log(`Google Sheet ${sheet.id} updated`);
  }
}
```

---

# 5. Планировщик задач (cron)

Создайте файл `src/scheduler.ts`:

```ts
import cron from "node-cron";
import { updateTariffs } from "./services/tariffsService";
import { updateGoogleSheetsForTariffs } from "./services/googleSheetsService";

function startScheduler() {
  // Например, обновлять тарифы каждый день в 01:00
  cron.schedule("0 1 * * *", async () => {
    try {
      console.log("Starting tariffs update...");
      await updateTariffs();

      const today = new Date();
      console.log("Starting Google Sheets update...");
      await updateGoogleSheetsForTariffs(today);

      console.log("All updates completed");
    } catch (error) {
      console.error("Error in scheduled task:", error);
    }
  });

  console.log("Scheduler started");
}

export default startScheduler;
```

---

# 6. Основной файл `app.ts`

```ts
import knex, { migrate, seed } from "#postgres/knex";
import startScheduler from "./scheduler";

async function main() {
  await migrate.latest();
  await seed.run();

  console.log("Migrations and seeds completed");

  // Запускаем планировщик
  startScheduler();
}

main().catch((e) => {
  console.error(e);
  process.exit(1);
});
```

---

# 7. Dockerfile и docker-compose

Убедитесь, что у вас в `Dockerfile` и `docker-compose.yml` правильно настроены env переменные, включая:

- POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD
- GOOGLE_SHEETS_CREDENTIALS (JSON сервисного аккаунта)
- Другие необходимые переменные.

---

# Итог

- Миграция создает таблицу тарифов.
- Сервис скачивает тарифы с Wildberries и сохраняет их в БД.
- Сервис обновляет Google Sheets по списку id таблиц.
- Планировщик запускает эти задачи по расписанию.
- Используется Knex.js для работы с PostgreSQL.
- Все типы на TypeScript.

---

Если нужно, могу помочь с конкретными частями — например, с миграциями, настройкой Google API, или тестами.  
Напишите, если хотите пример docker-compose или помощь с OAuth2 для Google Sheets.


Спасибо за предоставленные `.env`, `docker-compose.yml` и `Dockerfile`. Проверим и подкорректируем, чтобы всё работало корректно.

---

## 1. Переменные окружения

В вашем `.env`:

```env
POSTGRES_PORT=5432
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

APP_PORT=5000

JWT_SECRET=eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjUwNTIwdjEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc2NTY3MDIyOSwiaWQiOiIwMTk3NmU0Yy1mZTgwLTc1NDAtODkyMi02NGE5ZWUzYTU4MzYiLCJpaWQiOjQ1OTExNjA5LCJvaWQiOjExMzA0NiwicyI6MTA3Mzc0MTgzMiwic2lkIjoiOTMyYzE3NmEtNTA4NS01YzZmLWJjMzMtNGU4NGNkZjU4ZDdlIiwidCI6ZmFsc2UsInVpZCI6NDU5MTE2MDl9.wDoH8FLdZu1049uPCmhx3UHaw28YJB-CylWeD2LgkpRZFIMlOsUlnlVmfmYKy__JWNjfbDkOtdJ69QpSD5EKag
```

**Рекомендация:**  
- Добавьте переменную `POSTGRES_HOST=postgres` (т.к. в `docker-compose` хост базы — это имя сервиса `postgres`).  
- Добавьте переменную `GOOGLE_SHEETS_CREDENTIALS` с JSON сервисного аккаунта Google в одну строку (экранируйте кавычки или используйте файл и монтируйте в контейнер).  
- Добавьте `APP_PORT=5000` (уже есть).

---

## 2. docker-compose.yml (вы назвали `compose.yaml`)

Ваша часть `services` для `postgres` и `app` в целом выглядит хорошо. Несколько замечаний:

- В `postgres`:

  ```yaml
  environment:
    - PGPORT=${POSTGRES_PORT}
    - POSTGRES_DB=${POSTGRES_DB}
    - POSTGRES_USER=${POSTGRES_USER}
    - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    - PGDATA=/var/lib/postgresql/data/pgdata
  ```

  Здесь `PGPORT` — это переменная окружения PostgreSQL? Обычно используется `POSTGRES_PORT`. Но в официальном образе `postgres` порт задаётся через `-p` в `ports`, а не через env.  
  Можно убрать `PGPORT` или заменить на `POSTGRES_PORT`.

- В `app`:

  ```yaml
  environment:
    POSTGRES_HOST: postgres
    POSTGRES_PORT: ${POSTGRES_PORT}
    POSTGRES_DB: ${POSTGRES_DB}
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    PORT: ${APP_PORT}
    NODE_ENV: production
    JWT_SECRET: ${JWT_SECRET}
  ```

  Всё корректно, только добавьте `GOOGLE_SHEETS_CREDENTIALS` сюда, если используете env переменную.

- Порты:

  ```yaml
  ports:
    - "5001:5000"
  ```

  Это значит, что снаружи будет доступен порт 5001, а внутри контейнера приложение слушает 5000 (согласно `APP_PORT`).

---

## 3. Dockerfile

Ваш `Dockerfile` выглядит хорошо и оптимально:

- `deps-prod` — установка зависимостей без devDependencies.
- `build` — установка devDependencies + сборка.
- `prod` — копирование только нужного для запуска.

**Рекомендация:**  
В `prod` образе нет копирования `.env` или других файлов конфигурации. Если вы хотите использовать `.env` внутри контейнера, лучше передавать переменные через `docker-compose` (что вы и делаете).

---

## 4. Резюме и пример доработок

### .env (пример)

```env
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

APP_PORT=5000

JWT_SECRET=eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjUwNTIwdjEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc2NTY3MDIyOSwiaWQiOiIwMTk3NmU0Yy1mZTgwLTc1NDAtODkyMi02NGE5ZWUzYTU4MzYiLCJpaWQiOjQ1OTExNjA5LCJvaWQiOjExMzA0NiwicyI6MTA3Mzc0MTgzMiwic2lkIjoiOTMyYzE3NmEtNTA4NS01YzZmLWJjMzMtNGU4NGNkZjU4ZDdlIiwidCI6ZmFsc2UsInVpZCI6NDU5MTE2MDl9.wDoH8FLdZu1049uPCmhx3UHaw28YJB-CylWeD2LgkpRZFIMlOsUlnlVmfmYKy__JWNjfbDkOtdJ69QpSD5EKag

GOOGLE_SHEETS_CREDENTIALS={"type":"service_account","project_id":"...","private_key_id":"...","private_key":"-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n","client_email":"...","client_id":"...","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_x509_cert_url":"..."}
```

> Внимание: JSON сервисного аккаунта нужно записать в одну строку, экранируя переносы `\n` и кавычки.

---

### docker-compose.yml (с доработками)

```yaml
version: "3.9"

networks:
  postgres-net:
    driver: bridge

volumes:
  postgres-vol:
    driver: local

services:
  postgres:
    container_name: postgres
    image: postgres:16.1-alpine
    environment:
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres-vol:/var/lib/postgresql/data
    networks:
      - postgres-net
    expose:
      - ${POSTGRES_PORT}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  app:
    container_name: app
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PORT: ${APP_PORT}
      NODE_ENV: production
      JWT_SECRET: ${JWT_SECRET}
      GOOGLE_SHEETS_CREDENTIALS: ${GOOGLE_SHEETS_CREDENTIALS}
    ports:
      - "5001:${APP_PORT}"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - postgres-net
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 5
    command: ["npm", "run", "start"]
    restart: unless-stopped
```

---

## 5. Дополнительные советы

- Для Google Sheets credentials лучше монтировать json файл в контейнер и читать из файла, чтобы не хранить длинный JSON в переменной окружения. Например:

```yaml
volumes:
  - ./google-credentials.json:/app/google-credentials.json:ro
```

- В коде инициализации Google API использовать чтение из файла:

```ts
import { google } from "googleapis";
import path from "path";

const auth = new google.auth.GoogleAuth({
  keyFile: path.join(__dirname, "../google-credentials.json"),
  scopes: ["https://www.googleapis.com/auth/spreadsheets"],
});
```

- Убедитесь, что в вашем TypeScript коде переменные окружения читаются через `process.env.POSTGRES_HOST` и т.п.

---

Если нужно, могу помочь с примером чтения Google credentials из файла или с настройкой Docker для этого.  
Также могу помочь проверить, что приложение корректно подключается к базе и Google Sheets.




Спасибо за предоставленные `.env`, `docker-compose.yml` и `Dockerfile`. Проверим и подкорректируем, чтобы всё работало корректно.

---

## 1. Переменные окружения

В вашем `.env`:

```env
POSTGRES_PORT=5432
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

APP_PORT=5000

JWT_SECRET=eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjUwNTIwdjEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc2NTY3MDIyOSwiaWQiOiIwMTk3NmU0Yy1mZTgwLTc1NDAtODkyMi02NGE5ZWUzYTU4MzYiLCJpaWQiOjQ1OTExNjA5LCJvaWQiOjExMzA0NiwicyI6MTA3Mzc0MTgzMiwic2lkIjoiOTMyYzE3NmEtNTA4NS01YzZmLWJjMzMtNGU4NGNkZjU4ZDdlIiwidCI6ZmFsc2UsInVpZCI6NDU5MTE2MDl9.wDoH8FLdZu1049uPCmhx3UHaw28YJB-CylWeD2LgkpRZFIMlOsUlnlVmfmYKy__JWNjfbDkOtdJ69QpSD5EKag
```

**Рекомендация:**  
- Добавьте переменную `POSTGRES_HOST=postgres` (т.к. в `docker-compose` хост базы — это имя сервиса `postgres`).  
- Добавьте переменную `GOOGLE_SHEETS_CREDENTIALS` с JSON сервисного аккаунта Google в одну строку (экранируйте кавычки или используйте файл и монтируйте в контейнер).  
- Добавьте `APP_PORT=5000` (уже есть).

---

## 2. docker-compose.yml (вы назвали `compose.yaml`)

Ваша часть `services` для `postgres` и `app` в целом выглядит хорошо. Несколько замечаний:

- В `postgres`:

  ```yaml
  environment:
    - PGPORT=${POSTGRES_PORT}
    - POSTGRES_DB=${POSTGRES_DB}
    - POSTGRES_USER=${POSTGRES_USER}
    - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    - PGDATA=/var/lib/postgresql/data/pgdata
  ```

  Здесь `PGPORT` — это переменная окружения PostgreSQL? Обычно используется `POSTGRES_PORT`. Но в официальном образе `postgres` порт задаётся через `-p` в `ports`, а не через env.  
  Можно убрать `PGPORT` или заменить на `POSTGRES_PORT`.

- В `app`:

  ```yaml
  environment:
    POSTGRES_HOST: postgres
    POSTGRES_PORT: ${POSTGRES_PORT}
    POSTGRES_DB: ${POSTGRES_DB}
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    PORT: ${APP_PORT}
    NODE_ENV: production
    JWT_SECRET: ${JWT_SECRET}
  ```

  Всё корректно, только добавьте `GOOGLE_SHEETS_CREDENTIALS` сюда, если используете env переменную.

- Порты:

  ```yaml
  ports:
    - "5001:5000"
  ```

  Это значит, что снаружи будет доступен порт 5001, а внутри контейнера приложение слушает 5000 (согласно `APP_PORT`).

---

## 3. Dockerfile

Ваш `Dockerfile` выглядит хорошо и оптимально:

- `deps-prod` — установка зависимостей без devDependencies.
- `build` — установка devDependencies + сборка.
- `prod` — копирование только нужного для запуска.

**Рекомендация:**  
В `prod` образе нет копирования `.env` или других файлов конфигурации. Если вы хотите использовать `.env` внутри контейнера, лучше передавать переменные через `docker-compose` (что вы и делаете).

---

## 4. Резюме и пример доработок

### .env (пример)

```env
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

APP_PORT=5000

JWT_SECRET=eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjUwNTIwdjEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc2NTY3MDIyOSwiaWQiOiIwMTk3NmU0Yy1mZTgwLTc1NDAtODkyMi02NGE5ZWUzYTU4MzYiLCJpaWQiOjQ1OTExNjA5LCJvaWQiOjExMzA0NiwicyI6MTA3Mzc0MTgzMiwic2lkIjoiOTMyYzE3NmEtNTA4NS01YzZmLWJjMzMtNGU4NGNkZjU4ZDdlIiwidCI6ZmFsc2UsInVpZCI6NDU5MTE2MDl9.wDoH8FLdZu1049uPCmhx3UHaw28YJB-CylWeD2LgkpRZFIMlOsUlnlVmfmYKy__JWNjfbDkOtdJ69QpSD5EKag

GOOGLE_SHEETS_CREDENTIALS={"type":"service_account","project_id":"...","private_key_id":"...","private_key":"-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n","client_email":"...","client_id":"...","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_x509_cert_url":"..."}
```

> Внимание: JSON сервисного аккаунта нужно записать в одну строку, экранируя переносы `\n` и кавычки.

---

### docker-compose.yml (с доработками)

```yaml
version: "3.9"

networks:
  postgres-net:
    driver: bridge

volumes:
  postgres-vol:
    driver: local

services:
  postgres:
    container_name: postgres
    image: postgres:16.1-alpine
    environment:
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres-vol:/var/lib/postgresql/data
    networks:
      - postgres-net
    expose:
      - ${POSTGRES_PORT}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  app:
    container_name: app
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PORT: ${APP_PORT}
      NODE_ENV: production
      JWT_SECRET: ${JWT_SECRET}
      GOOGLE_SHEETS_CREDENTIALS: ${GOOGLE_SHEETS_CREDENTIALS}
    ports:
      - "5001:${APP_PORT}"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - postgres-net
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 5
    command: ["npm", "run", "start"]
    restart: unless-stopped
```

---

## 5. Дополнительные советы

- Для Google Sheets credentials лучше монтировать json файл в контейнер и читать из файла, чтобы не хранить длинный JSON в переменной окружения. Например:

```yaml
volumes:
  - ./google-credentials.json:/app/google-credentials.json:ro
```

- В коде инициализации Google API использовать чтение из файла:

```ts
import { google } from "googleapis";
import path from "path";

const auth = new google.auth.GoogleAuth({
  keyFile: path.join(__dirname, "../google-credentials.json"),
  scopes: ["https://www.googleapis.com/auth/spreadsheets"],
});
```

- Убедитесь, что в вашем TypeScript коде переменные окружения читаются через `process.env.POSTGRES_HOST` и т.п.

---

Если нужно, могу помочь с примером чтения Google credentials из файла или с настройкой Docker для этого.  
Также могу помочь проверить, что приложение корректно подключается к базе и Google Sheets.

Понял, что у вас пока нет реальных ключей Google Sheets, и вы для отладки указали в `.env`:

```env
GOOGLE_SHEETS_CREDENTIALS='any'
```

---

### Что важно знать и делать в таком случае:

1. **Передача переменной GOOGLE_SHEETS_CREDENTIALS с фиктивным значением — допустима для разработки**, но при попытке обращения к Google Sheets API приложение, скорее всего, упадёт с ошибкой аутентификации.

2. **Если вы не используете Google Sheets API сейчас, то можно временно убрать эту переменную из `docker-compose.yml` и кода**, чтобы не было ошибок.

3. **Если код ожидает переменную `GOOGLE_SHEETS_CREDENTIALS` — можно передать заглушку, но лучше в коде предусмотреть обработку отсутствия реальных ключей**, например:

```ts
const googleSheetsCreds = process.env.GOOGLE_SHEETS_CREDENTIALS;

if (!googleSheetsCreds || googleSheetsCreds === 'any') {
  console.warn('Google Sheets credentials not provided, skipping API initialization');
  // не инициализируем Google API
} else {
  // инициализация Google API с реальными creds
}
```

4. **В `docker-compose.yml` можно оставить переменную, как есть:**

```yaml
environment:
  ...
  GOOGLE_SHEETS_CREDENTIALS: ${GOOGLE_SHEETS_CREDENTIALS}
```

а в `.env`:

```env
GOOGLE_SHEETS_CREDENTIALS=any
```

(без кавычек, чтобы не попадали в значение).

---

### Итог:

- Для работы с Google Sheets нужен реальный JSON сервисного аккаунта.  
- Пока его нет — можно передавать заглушку или не передавать переменную вовсе.  
- В коде нужно предусмотреть обработку отсутствия валидных ключей, чтобы приложение не падало.  
- Как только получите ключи — замените `GOOGLE_SHEETS_CREDENTIALS` в `.env` на настоящий JSON (в одну строку, с экранированием).

Если хотите, могу помочь написать пример кода, который безопасно обрабатывает отсутствие ключей и инициализирует Google API только при наличии валидных данных.


Отлично, что вы поставили заглушку в виде JSON с ключами — это лучше, чем просто `'any'`, потому что структура похожа на реальную.

Однако, чтобы всё работало корректно, обратите внимание на несколько важных моментов:

---

### 1. Формат переменной окружения GOOGLE_SHEETS_CREDENTIALS

Переменная должна содержать **валидный JSON в одну строку** с корректным экранированием, особенно для многострочного поля `private_key`.

Пример (упрощённый):

```env
GOOGLE_SHEETS_CREDENTIALS={"type":"service_account","project_id":"my-project","private_key_id":"abc123","private_key":"-----BEGIN PRIVATE KEY-----\\nMIIEv...\\n-----END PRIVATE KEY-----\\n","client_email":"my-email@my-project.iam.gserviceaccount.com","client_id":"1234567890","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_x509_cert_url":"https://www.googleapis.com/robot/v1/metadata/x509/my-email%40my-project.iam.gserviceaccount.com"}
```

Обратите внимание:

- Переносы строки в `private_key` заменены на `\\n` (двойной слэш + n), чтобы корректно передавать в env.

- В `.env` **не используйте одинарные или двойные кавычки вокруг всего JSON**, иначе они попадут в значение переменной.

---

### 2. Как использовать в коде

В коде вы можете распарсить JSON из переменной окружения:

```ts
let googleSheetsCredentials;

try {
  googleSheetsCredentials = JSON.parse(process.env.GOOGLE_SHEETS_CREDENTIALS || '{}');
} catch (e) {
  console.error('Failed to parse GOOGLE_SHEETS_CREDENTIALS:', e);
  googleSheetsCredentials = null;
}

if (googleSheetsCredentials && googleSheetsCredentials.type === 'service_account') {
  // Инициализируем Google API с этими ключами
} else {
  console.warn('Google Sheets credentials not valid or missing, skipping initialization');
}
```

---

### 3. Если у вас пока нет реальных ключей

- Можно оставить фиктивные данные, но Google API вызовы будут падать с ошибкой аутентификации.

- Для разработки можно заглушить вызовы Google Sheets API, чтобы приложение не падало.

---

### 4. Вывод

- Проверьте, что в `.env` переменная `GOOGLE_SHEETS_CREDENTIALS` записана корректно (одна строка, экранирование `\n` как `\\n`).

- В коде обязательно парсите JSON и обрабатывайте ошибки.

- При реальном использовании замените заглушку на настоящий JSON сервисного аккаунта.

---

Если нужно, могу помочь с примером скрипта, который подготавливает JSON из файла в строку для `.env`, или с примером кода инициализации Google Sheets API.


Судя по выводу `docker-compose up`, контейнер `postgres` успешно запущен, база готова принимать подключения, а контейнер `app` стартовал и выполнил миграции и сиды без ошибок.

Это значит, что проблема с ошибкой `getaddrinfo ENOTFOUND postgres` **исчезла**, потому что теперь база доступна в сети Docker Compose под именем `postgres`.

---

### Что делать дальше

- Продолжайте запускать контейнеры через `docker-compose up` — так гарантируется, что база и приложение запускаются вместе и приложение видит базу по имени `postgres`.
- Если хотите запускать контейнеры в фоне, используйте:

  ```bash
  docker-compose up -d
  ```

- Если приложение запускается локально (вне Docker), помните, что имя `postgres` не резолвится — используйте `localhost` и порт, проброшенный из контейнера.

---

### Краткий вывод

- Ошибка была вызвана тем, что контейнер базы был остановлен.
- Теперь база запущена и приложение к ней подключается успешно.
- Всё работает корректно.

Если появятся новые вопросы — обращайтесь!

Ошибка `getaddrinfo ENOTFOUND postgres` при запуске через `npm run dev` локально (вне Docker) возникает потому, что имя хоста `postgres` не резолвится в вашей системе. В Docker Compose имя `postgres` работает, потому что это имя сервиса в Docker-сети, но на хост-машине оно неизвестно.

---

## Почему так происходит

- Когда вы запускаете приложение командой `docker-compose up`, оно работает внутри Docker-сети, где `postgres` — это имя контейнера, и DNS резолвит его.
- При запуске `npm run dev` локально (например, на MacBook) приложение работает вне Docker, и имя `postgres` не резолвится в IP, поэтому возникает ошибка.

---

## Как исправить

### 1. Используйте разные настройки подключения к базе для локальной разработки и для Docker

- В `.env` или конфиге для Docker:

  ```
  POSTGRES_HOST=postgres
  ```

- В `.env.local` (или аналогичном файле для локального запуска):

  ```
  POSTGRES_HOST=localhost
  ```

### 2. Пробросьте порт PostgreSQL из контейнера на локальную машину

В вашем `docker-compose.yml` в сервисе `postgres` должен быть проброшен порт, например:

```yaml
ports:
  - "5432:5432"
```

Это позволит подключаться к базе на `localhost:5432` из локального приложения.

---

### 3. Запускайте PostgreSQL контейнер отдельно, чтобы база была доступна локально

```bash
docker-compose up -d postgres
```

Теперь локальное приложение сможет подключаться к `localhost:5432`.

---

### 4. Проверьте, что приложение использует правильный хост при локальном запуске

Например, в коде или конфиге:

```ts
const dbHost = process.env.POSTGRES_HOST || 'localhost';
```

---

## Итог

- Запуская приложение локально (через `npm run dev`), используйте `POSTGRES_HOST=localhost`.
- Запуская приложение в Docker — используйте `POSTGRES_HOST=postgres`.
- Убедитесь, что порт 5432 проброшен из контейнера.
- Запустите базу командой `docker-compose up -d postgres` перед локальным запуском приложения.

Так вы устраните ошибку `ENOTFOUND postgres` при локальном запуске.

Если нужна помощь с конфигурацией `.env` или `docker-compose.yml` — напишите, помогу!

Да, вы всё правильно понимаете:

- **В Docker** ваше приложение и база запускаются вместе, имя хоста `postgres` резолвится корректно, миграции и сиды отрабатывают — значит, сервис по части работы с БД и обновления данных работает как задумано.

- **Локально (вне Docker)** ошибка `getaddrinfo ENOTFOUND postgres` возникает именно из-за того, что имя `postgres` не известно вашей системе. Это нормальная ситуация, когда приложение настроено на подключение к базе в Docker-сети.

---

### Итог по заданию

- Если вы проверяли работу сервиса **через Docker Compose**, и он успешно:

  - Получает и сохраняет информацию о тарифах Wildberries в базу,
  - Обновляет данные в Google-таблицах,
  - Миграции и сиды отрабатывают без ошибок,

  — значит, **задание выполнено полностью и корректно**.

---

### Что можно сделать дополнительно (опционально)

- Добавить в проект отдельные конфигурации для локальной разработки и для продакшена (Docker), чтобы запускать приложение локально без ошибок (через `localhost` вместо `postgres`).
- Настроить переменные окружения и документацию, чтобы было понятно, как запускать сервис в разных средах.

---

Если хотите, могу помочь с примером такой конфигурации или проверить код по задачам — дайте знать!

Этот сервис работает с тарифами Wildberries и реализует следующие основные методы:

1. **fetchTariffsFromWB()**  
   - Делает HTTP GET-запрос к публичному API Wildberries по адресу `https://common-api.wildberries.ru/api/v1/tariffs/box`.  
   - Получает и возвращает массив тарифов (`Tariff[]`), которые приходят в ответе от API.

2. **saveTariffsToDB(tariffs, date)**  
   - Принимает массив тарифов и дату.  
   - Для каждого тарифа сохраняет или обновляет запись в таблице `tariffs` базы данных PostgreSQL с помощью `knex`.  
   - Использует UPSERT (через `ON CONFLICT` по уникальному ключу `tariff_id` и `date`), чтобы при совпадении обновлять существующие данные, иначе вставлять новые.  
   - Сохраняет поля: `tariff_id`, `name`, `price`, `raw_data` (исходные данные в JSON), дату и время последнего обновления.

3. **updateTariffs()**  
   - Основная функция обновления тарифов.  
   - Вызывает `fetchTariffsFromWB()` для получения актуальных тарифов.  
   - Формирует текущую дату без времени (только год-месяц-день).  
   - Вызывает `saveTariffsToDB()` для сохранения тарифов в базу с этой датой.  
   - Логирует сообщение об успешном обновлении тарифов на текущую дату.

---

### В итоге

Сервис регулярно получает актуальные тарифы Wildberries через API, сохраняет их в базу данных с отметкой по дате, обновляя существующие записи при необходимости. Это позволяет хранить историю тарифов по датам и иметь доступ к актуальным данным для дальнейшей работы.

я правильно понимаю что он получил данные от этого ключа const WB_TARIFFS_URL = "https://common-api.wildberries.ru/api/v1/tariffs/box";и от сюда ведет проверку ? так 

Да, вы правильно понимаете.

- Константа `WB_TARIFFS_URL = "https://common-api.wildberries.ru/api/v1/tariffs/box"` — это URL публичного API Wildberries, откуда сервис получает данные о тарифах.
- Метод `fetchTariffsFromWB()` делает запрос именно по этому адресу и получает актуальные тарифы.
- Далее сервис сохраняет или обновляет эти тарифы в базе данных, чтобы иметь актуальную и историческую информацию.

Таким образом, именно с этого URL сервис получает исходные данные для своей работы и "ведёт проверку" (то есть обновляет тарифы в базе) на основе этих данных.

Хороший вопрос!

---

## Почему `JWT_SECRET` из `.env` не используется в вашем коде с тарифами?

В приведённом вами коде сервиса, который работает с тарифами Wildberries, **переменная `JWT_SECRET` вообще не используется**.

- Код только делает HTTP-запрос к публичному API Wildberries по URL `https://common-api.wildberries.ru/api/v1/tariffs/box` — там, судя по всему, **не требуется авторизация или токен**.
- В коде нет никаких мест, где бы использовался JWT или заголовки авторизации с этим секретом.

---

## Где и как обычно используется `JWT_SECRET`

- `JWT_SECRET` — это секретный ключ для подписи и проверки JWT-токенов (JSON Web Tokens).
- Обычно он применяется в сервисах, которые реализуют **аутентификацию и авторизацию пользователей**.
- Например, при логине сервер генерирует JWT с помощью этого секрета, а при последующих запросах проверяет подпись токена.
- В вашем проекте `JWT_SECRET` может использоваться в другом модуле, например, в API-сервере, который обслуживает пользователей, защищает маршруты, выдаёт токены и т.п.

---

## Что делать, если хотите использовать `JWT_SECRET`

- Убедитесь, что в коде, который работает с JWT (например, в middleware аутентификации или в модуле авторизации), есть импорт и чтение переменной окружения `process.env.JWT_SECRET`.
- Пример использования (Node.js с библиотекой jsonwebtoken):

```ts
import jwt from "jsonwebtoken";

const secret = process.env.JWT_SECRET;

function verifyToken(token: string) {
  try {
    return jwt.verify(token, secret);
  } catch (err) {
    throw new Error("Invalid token");
  }
}
```

---

## Кратко по остальным переменным из `.env`

- `POSTGRES_*` — параметры подключения к базе данных (порт, имя базы, пользователь, пароль, хост).
- `APP_PORT` — порт, на котором запускается ваше приложение.
- `JWT_SECRET` — секрет для подписи JWT, используется в модулях аутентификации.

---

## Итог

- В вашем сервисе получения и сохранения тарифов `JWT_SECRET` не нужен и не используется.
- `JWT_SECRET` нужен в тех частях приложения, где реализована работа с JWT (авторизация, аутентификация).
- Если в проекте есть такие части — там и надо подключать `JWT_SECRET` из `.env`.

Если хотите, могу помочь с примером кода для работы с JWT или объяснить, как интегрировать авторизацию в ваш проект.

Спасибо за уточнение задачи. Исходя из вашего описания, давайте разберём, что должен делать сервис и как к этому относится файл с переменными и кодом.

---

## Задачи сервиса

1. **Регулярное получение тарифов Wildberries (каждые 12 часов)**  
   - Делать запрос к публичному API по адресу `https://common-api.wildberries.ru/api/v1/tariffs/box`.  
   - Сохранять полученные тарифы в PostgreSQL с отметкой даты (по дням).

2. **Регулярное обновление информации в Google-таблицах (каждые 6 часов)**  
   - Извлекать данные из PostgreSQL.  
   - Обновлять данные в Google Sheets по их идентификаторам (таблиц может быть несколько).  
   - Для работы с Google Sheets потребуется авторизация через Google API.

---

## Отношение переменной `JWT_SECRET` к задаче

- Ваша задача не требует авторизации при получении тарифов Wildberries — API публичный, поэтому `JWT_SECRET` для этого не нужен.
- Однако для работы с Google Sheets обычно требуется OAuth 2.0 или сервисный аккаунт, где используются ключи и токены — возможно, в вашем проекте `JWT_SECRET` задуман как секрет для подписи JWT, если реализована внутренняя авторизация или аутентификация сервисов.
- Если в проекте нет авторизации пользователей и нет JWT-авторизации, то `JWT_SECRET` может быть лишним или предназначенным для будущих расширений.

---

## Что должно быть реализовано дополнительно для Google Sheets

- Модуль, который по расписанию (например, с помощью `node-cron` или другого планировщика) каждые 6 часов:  
  - Читает актуальные тарифы из PostgreSQL.  
  - Подключается к Google Sheets API с использованием Google credentials (OAuth 2.0 или сервисный аккаунт).  
  - Обновляет данные в нужных таблицах по их идентификаторам.

- Для этого обычно нужна отдельная конфигурация с ключами доступа Google, которые могут храниться в `.env` или в отдельных JSON-файлах.

---

## Работа с Docker и переменными окружения

- В Docker Compose вы правильно передаёте параметры подключения к базе (`POSTGRES_HOST`, `POSTGRES_USER`, `POSTGRES_PASSWORD` и т.п.).
- Переменная `JWT_SECRET` должна быть передана в контейнер, если она действительно используется в коде (например, для авторизации).
- Если `JWT_SECRET` не используется, её можно убрать или оставить для будущих задач.

---

## Итог — что должно быть в вашем проекте

- **Модуль для получения тарифов WB по URL и сохранения в PostgreSQL (каждые 12 часов).**  
  Ваш текущий код с `fetchTariffsFromWB` и `saveTariffsToDB` соответствует этому.

- **Модуль для обновления Google Sheets (каждые 6 часов).**  
  Этот модуль нужно реализовать отдельно, используя Google API и данные из базы.

- **Планировщик задач (cron или аналог) для запуска этих операций по расписанию.**

- **Правильное использование переменных окружения:**  
  - DB-параметры — для подключения к PostgreSQL.  
  - Google API credentials — для доступа к Google Sheets.  
  - JWT_SECRET — только если у вас есть JWT-авторизация.

---
Ваши комментарии по смыслу понятны и отражают логику функций, но их можно сделать более лаконичными, стилистически единообразными и чуть более формальными — это улучшит читаемость и поддержку кода, особенно в командной разработке.

Вот пример, как можно отрефакторить ваши комментарии, сохранив суть, но сделав их более «каноничными» для TypeScript/JavaScript:

```ts
import axios from "axios";
import knex from "#postgres/knex";
import { Tariff } from "#types/tariffs";

const WB_TARIFFS_URL = "https://common-api.wildberries.ru/api/v1/tariffs/box";

/**
 * Fetches tariffs from Wildberries public API.
 * @returns {Promise<Tariff[]>} Array of tariffs.
 */
export async function fetchTariffsFromWB(): Promise<Tariff[]> {
  const response = await axios.get(WB_TARIFFS_URL);
  return response.data; // предполагается, что API возвращает массив тарифов
}

/**
 * Saves tariffs into the database for a given date.
 * Uses upsert (ON CONFLICT) to insert or update existing records.
 * @param {Tariff[]} tariffs - Array of tariffs to save.
 * @param {Date} date - Date for which tariffs are saved (date only, no time).
 */
export async function saveTariffsToDB(
  tariffs: Tariff[],
  date: Date
): Promise<void> {
  for (const tariff of tariffs) {
    await knex("tariffs")
      .insert({
        tariff_id: tariff.tariff_id,
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        date,
      })
      .onConflict(["tariff_id", "date"])
      .merge({
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        updated_at: knex.fn.now(),
      });
  }
}

/**
 * Fetches latest tariffs from Wildberries and saves them to DB for today's date.
 * Logs a message on completion.
 */
export async function updateTariffs(): Promise<void> {
  const tariffs = await fetchTariffsFromWB();
  const today = new Date();
  const dateString = today.toISOString().split("T")[0]; // yyyy-mm-dd
  await saveTariffsToDB(tariffs, new Date(dateString));
  console.log(`Tariffs updated for date ${dateString}`);
}
```

---

### Рекомендации:

- Используйте JSDoc-стиль комментариев `/** ... */` для описания функций и параметров — это удобно для IDE и автогенерации документации.
- Избегайте излишне разговорных формулировок, лучше формулируйте кратко и по делу.
- Объясняйте, что делает функция, что ожидает на входе и что возвращает.
- В теле функций комментарии нужны только если логика не очевидна.

---

Да, в моём примере использован формат JSDoc — это комментарии в виде блоков `/** ... */` с описанием функции, параметров и возвращаемого значения. Такой стиль хорошо поддерживается редакторами и инструментами документации.

Ниже пример тех же комментариев, но на русском языке и в формате JSDoc:

```ts
import axios from "axios";
import knex from "#postgres/knex";
import { Tariff } from "#types/tariffs";

const WB_TARIFFS_URL = "https://common-api.wildberries.ru/api/v1/tariffs/box";

/**
 * Получает тарифы из публичного API Wildberries.
 * @returns {Promise<Tariff[]>} Массив тарифов.
 */
export async function fetchTariffsFromWB(): Promise<Tariff[]> {
  const response = await axios.get(WB_TARIFFS_URL);
  return response.data; // предполагается, что API возвращает массив тарифов
}

/**
 * Сохраняет тарифы в базу данных для указанной даты.
 * Использует upsert (ON CONFLICT) для вставки или обновления записей.
 * @param {Tariff[]} tariffs - Массив тарифов для сохранения.
 * @param {Date} date - Дата, на которую сохраняются тарифы (только дата без времени).
 */
export async function saveTariffsToDB(
  tariffs: Tariff[],
  date: Date
): Promise<void> {
  for (const tariff of tariffs) {
    await knex("tariffs")
      .insert({
        tariff_id: tariff.tariff_id,
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        date,
      })
      .onConflict(["tariff_id", "date"])
      .merge({
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        updated_at: knex.fn.now(),
      });
  }
}

/**
 * Обновляет тарифы: получает актуальные данные из Wildberries и сохраняет их в базу на текущую дату.
 * По завершении выводит сообщение в консоль.
 */
export async function updateTariffs(): Promise<void> {
  const tariffs = await fetchTariffsFromWB();
  const today = new Date();
  const dateString = today.toISOString().split("T")[0]; // yyyy-mm-dd
  await saveTariffsToDB(tariffs, new Date(dateString));
  console.log(`Tariffs updated for date ${dateString}`);
}
```

Такой стиль комментариев понятен, формален и удобен для поддержки. Если хотите — могу помочь с генерацией документации или интеграцией с IDE.


Давайте по порядку.

---

### 1. Обновление тарифов каждые 12 часов

В вашем текущем коде:

```ts
const dateString = today.toISOString().split("T")[0]; // yyyy-mm-dd
await saveTariffsToDB(tariffs, new Date(dateString));
```

вы сохраняете тарифы **по дате без времени**, то есть фактически один раз в день. Если хотите обновлять тарифы **каждые 12 часов**, то нужно:

- Либо сохранять дату с точностью до времени (например, дата + время в часах),
- Либо использовать планировщик задач (cron, node-cron, или системный cron) чтобы запускать функцию `updateTariffs` каждые 12 часов.

**Где это делается?**

- Запускать периодически функцию `updateTariffs` нужно вне этого скрипта — обычно в отдельном сервисе, планировщике задач или в процессе, который работает постоянно.
- В самом скрипте вы просто реализуете логику получения и сохранения тарифов.

**Пример запуска каждые 12 часов с node-cron:**

```ts
import cron from 'node-cron';

cron.schedule('0 */12 * * *', async () => {
  await updateTariffs();
  console.log('Tariffs updated every 12 hours');
});
```

Это запускает `updateTariffs` в 0 минут каждого 12-го часа (например, в 00:00 и 12:00).

---

### 2. Ошибка 401 Unauthorized и заголовок Authorization

Ответ с ошибкой:

```json
{
  "title": "unauthorized",
  "detail": "empty Authorization header",
  "code": "...",
  "status": 401,
  "statusText": "Unauthorized"
}
```

означает, что API требует **авторизационный заголовок** — вы должны передавать токен или ключ в HTTP заголовке `Authorization`.

Пример, как добавить заголовок в axios:

```ts
const response = await axios.get(WB_TARIFFS_URL, {
  headers: {
    Authorization: 'Bearer YOUR_ACCESS_TOKEN_HERE'
  }
});
```

Или, если API требует другой формат, то согласно документации.

---

### 3. Про объект из API и объект для сохранения в БД

Вы показали пример объекта ошибки от API, он не похож на тарифы, которые вы сохраняете.

- **Объект из API** — это данные, которые вы получаете (тарифы).
- **Объект, который вы сохраняете в БД** — это ваша внутренняя структура, куда вы кладёте нужные поля из полученных тарифов.

То есть:

- Объекты, которые вы сохраняете в `saveTariffsToDB`, должны соответствовать структуре таблицы `tariffs`.
- Объекты, которые вы получаете от API, могут иметь другую структуру.

Вы **не должны** сохранять в БД объект ошибки API. Если пришла ошибка 401 — нужно обработать её отдельно (например, выбросить исключение, залогировать и прервать сохранение).

---

### Итог:

- Для запуска обновления каждые 12 часов используйте внешний планировщик (cron, node-cron и т.п.).
- В запросе к API добавьте заголовок Authorization с токеном.
- Обрабатывайте ошибки API отдельно, не сохраняйте объекты ошибок в базу.
- В `saveTariffsToDB` сохраняйте только корректные объекты тарифов, соответствующие вашей таблице.

---

Если хотите, могу помочь написать пример с авторизацией в axios и пример с node-cron для запуска по расписанию.


Спасибо за уточнение!

---

### Несколько важных моментов по вашему JWT_SECRET из `.env`

1. **JWT_SECRET — это обычно секретный ключ для генерации или проверки JWT-токенов на вашем сервере**, а не сам токен для авторизации в API.

2. Чтобы авторизоваться в API Wildberries, вам нужен **сам JWT-токен**, который обычно получается через отдельный процесс аутентификации (например, логин/пароль, OAuth, или иной механизм), либо вам его выдают отдельно как Access Token.

3. Если в `.env` у вас хранится именно секрет (ключ), а не токен, то вы не можете просто вставить его в заголовок `Authorization: Bearer <JWT_SECRET>`, потому что API ожидает **валидный токен**, а не секрет.

---

### Что делать?

- Проверьте документацию API Wildberries — как именно получить токен для авторизации.
- Возможно, вам нужно сделать запрос на получение токена (например, передать логин/пароль или ключ API), и получить от API JWT-токен.
- После этого вы используете полученный токен в заголовке `Authorization: Bearer <полученный_токен>`.

---

### Как использовать токен в axios

```ts
import dotenv from 'dotenv';
dotenv.config();

const token = process.env.WB_ACCESS_TOKEN; // токен, а не секрет

const response = await axios.get(WB_TARIFFS_URL, {
  headers: {
    Authorization: `Bearer ${token}`
  }
});
```

---

### Если у вас только JWT_SECRET, и вы хотите сами сформировать токен

- Это возможно, если API принимает самоподписанные JWT, но это редкий кейс.
- Для этого нужно знать, какие данные (payload) и с каким алгоритмом подписывать.
- Обычно это не так, и токен нужно получать у API.

---

### Итог

- **JWT_SECRET из `.env` — это не токен, а ключ.**
- Для доступа к API нужен именно **токен (JWT Access Token)**.
- Получите токен по инструкции Wildberries и используйте его в заголовке Authorization.
- Если нужна помощь с получением токена — покажите документацию или опишите, как вы пытаетесь его получить.

---

Если хотите, могу помочь написать пример запроса для получения токена (если у вас есть данные для аутентификации) и последующего вызова API с этим токеном.

когда мен прислали тест то написали что  я получу API ключ и вот они мне его прислали Спасибо!
Высылаем ключ:
eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjUwNTIwdjEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc2NTY3MDIyOSwiaWQiOiIwMTk3NmU0Yy1mZTgwLTc1NDAtODkyMi02NGE5ZWUzYTU4MzYiLCJpaWQiOjQ1OTExNjA5LCJvaWQiOjExMzA0NiwicyI6MTA3Mzc0MTgzMiwic2lkIjoiOTMyYzE3NmEtNTA4NS01YzZmLWJjMzMtNGU4NGNkZjU4ZDdlIiwidCI6ZmFsc2UsInVpZCI6NDU5MTE2MDl9.wDoH8FLdZu1049uPCmhx3UHaw28YJB-CylWeD2LgkpRZFIMlOsUlnlVmfmYKy__JWNjfbDkOtdJ69QpSD5EKag - но ты говоришь что это не то?

Спасибо за уточнение, теперь всё понятнее.

---

### Что вы получили — это и есть ваш API ключ (JWT-токен)

То, что вам прислали — длинная строка, похожая на JWT (три части через точки) — это **ваш API ключ**, то есть **JWT Access Token**, который нужно передавать в заголовке `Authorization`.

---

### Как использовать этот ключ

В вашем запросе к API Wildberries нужно передавать именно этот токен в заголовке:

```ts
const token = process.env.JWT_SECRET; // у вас в .env лежит этот ключ

const response = await axios.get(WB_TARIFFS_URL, {
  headers: {
    Authorization: `Bearer ${token}`
  }
});
```

---

### Почему я говорил, что JWT_SECRET — это не токен?

Потому что обычно в переменной с именем `JWT_SECRET` хранят именно **секретный ключ** для подписи JWT, а не сам токен. Но в вашем случае переменная названа `JWT_SECRET`, а на самом деле в ней лежит **полученный JWT-токен**, который нужно использовать как Access Token.

---

### Что делать, чтобы убрать ошибку 401?

1. Убедитесь, что в коде вы используете именно этот токен из `.env` в заголовке `Authorization: Bearer <токен>`.
2. Проверьте, что переменная окружения загружается корректно (например, через `console.log(process.env.JWT_SECRET)`).
3. Проверьте, что заголовок передаётся именно так — с префиксом `Bearer ` и без лишних пробелов.
4. Если всё сделано правильно, API должен принять запрос и не возвращать 401.

---

### Пример полного запроса с axios:

```ts
import axios from 'axios';
import dotenv from 'dotenv';
dotenv.config();

const WB_TARIFFS_URL = 'https://suppliers-api.wildberries.ru/api/v1/info/tariffs';
const token = process.env.JWT_SECRET;

async function getTariffs() {
  try {
    const response = await axios.get(WB_TARIFFS_URL, {
      headers: {
        Authorization: `Bearer ${token}`
      }
    });
    console.log('Tariffs:', response.data);
  } catch (error) {
    console.error('Error fetching tariffs:', error.response?.data || error.message);
  }
}

getTariffs();
```

---

Если после этого ошибка 401 остаётся, возможно:

- Токен устарел или отозван — нужно запросить новый.
- В API есть дополнительные требования (например, IP-ограничения, другие заголовки).
- Вы вызываете неправильный URL или метод.

---

Если хотите, могу помочь проверить ваш код или подсказать, как правильно настроить `.env` и axios.


Почти — в вашем коде **в запросе к API отсутствует заголовок Authorization с токеном**, из-за чего вы и получаете 401.

Нужно добавить в функцию `fetchTariffsFromWB` передачу заголовка с токеном из `.env` (который у вас в `process.env.JWT_SECRET`):

```ts
export async function fetchTariffsFromWB(): Promise<Tariff[]> {
  const response = await axios.get(WB_TARIFFS_URL, {
    headers: {
      Authorization: `Bearer ${token}`
    }
  });
  return response.data;
}
```

---

### Полный исправленный пример с комментариями:

```ts
import axios from "axios";
import dotenv from "dotenv";
import knex from "#postgres/knex";
import { Tariff } from "#types/tariffs";

dotenv.config();

const WB_TARIFFS_URL = "https://common-api.wildberries.ru/api/v1/tariffs/box";
const token = process.env.JWT_SECRET;

export async function fetchTariffsFromWB(): Promise<Tariff[]> {
  if (!token) {
    throw new Error("JWT token is not defined in environment variable JWT_SECRET");
  }

  const response = await axios.get(WB_TARIFFS_URL, {
    headers: {
      Authorization: `Bearer ${token}`
    }
  });
  return response.data;
}

export async function saveTariffsToDB(
  tariffs: Tariff[],
  date: Date
): Promise<void> {
  for (const tariff of tariffs) {
    await knex("tariffs")
      .insert({
        tariff_id: tariff.tariff_id,
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        date,
      })
      .onConflict(["tariff_id", "date"])
      .merge({
        name: tariff.name,
        price: tariff.price,
        raw_data: JSON.stringify(tariff),
        updated_at: knex.fn.now(),
      });
  }
}

export async function updateTariffs(): Promise<void> {
  const tariffs = await fetchTariffsFromWB();
  const today = new Date();
  const dateString = today.toISOString().split("T")[0];
  await saveTariffsToDB(tariffs, new Date(dateString));
  console.log(`Tariffs updated for date ${dateString}`);
}
```

---

### Итог

- Обязательно передавайте заголовок `Authorization: Bearer <token>`.
- Проверьте, что в `.env` переменная `JWT_SECRET` содержит именно ваш JWT-токен.
- Если токен устарел — запросите новый у Wildberries.
- Ваш код сохранения и обновления в базе выглядит корректно.

Если нужна помощь с отладкой — пишите!


Promise<void> в сигнатуре функции
Это указывает, что функция асинхронная (работает с Promise), но не возвращает значимого значения при успешном выполнении.


Когда используют Promise<void>?
Для асинхронных операций, которые не возвращают данных, но нужно дождаться их завершения:

Запись в файл/БД.

Отправка HTTP-запроса без ожидания ответа.

Логирование.

Действия в Google Sheets (например, обновление ячеек).




При создании новых миграций используется:

bash
npm run migrate:make migration_name